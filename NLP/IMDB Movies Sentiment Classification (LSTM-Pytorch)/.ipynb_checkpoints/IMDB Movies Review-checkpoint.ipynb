{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to this challenge: https://www.kaggle.com/c/word2vec-nlp-tutorial/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do to improve the model:\n",
    "    - Preprocessing data (trim off common words such as \"the\", \"a\", ...\n",
    "    - Increasing vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:16:17.842309Z",
     "start_time": "2020-04-04T17:16:16.952317Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:16:51.682585Z",
     "start_time": "2020-04-04T15:16:51.660108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:16:51.691536Z",
     "start_time": "2020-04-04T15:16:51.683558Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/labeledTrainData.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:16:52.830971Z",
     "start_time": "2020-04-04T15:16:52.044076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Field \n",
    "TEXT = data.Field(tokenize=\"spacy\", include_lengths=True)\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:16:52.836957Z",
     "start_time": "2020-04-04T15:16:52.832966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create fields based on the data table\n",
    "fields = [(None,None),(\"label\", LABEL),(\"text\",TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:25.204467Z",
     "start_time": "2020-04-04T15:16:52.837953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Tabular dataset\n",
    "dataset = data.TabularDataset(path=DATA_DIR,format=\"tsv\", fields = fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:25.233323Z",
     "start_time": "2020-04-04T15:17:25.205368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 22500\n",
      "Number of validating samples: 2500\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and validating set\n",
    "trainset, valset = dataset.split(split_ratio=0.9)\n",
    "print(f\"Number of training samples: {len(trainset)}\")\n",
    "print(f\"Number of validating samples: {len(valset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:25.385061Z",
     "start_time": "2020-04-04T15:17:25.234290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if data have been read properly\n",
    "#print(vars(trainset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.906989Z",
     "start_time": "2020-04-04T15:17:25.391045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the vocabulary on the training set, using pre-trained embedding layer (word2vector)\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "TEXT.build_vocab(trainset,\n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.911942Z",
     "start_time": "2020-04-04T15:17:26.907953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 20002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "# The vocabulary automatically add <pad> and <unk> tokens so that the size increases by 2\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.918924Z",
     "start_time": "2020-04-04T15:17:26.912940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show 10 most common words on the training vocabulary\n",
    "#print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.924936Z",
     "start_time": "2020-04-04T15:17:26.919921Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# Load dataset into iterator, sort the data by the length of words (required for packed sequence in the model)\n",
    "train_iter, valid_iter = data.BucketIterator.splits(\n",
    "    (trainset, valset), \n",
    "    sort_within_batch = True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "attachments": {
    "architecture.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:16:44.229897Z",
     "start_time": "2020-04-04T17:16:44.217928Z"
    }
   },
   "source": [
    "![architecture.png](attachment:architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.932887Z",
     "start_time": "2020-04-04T15:17:26.925905Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim ,\n",
    "                 n_layers, bidirectional, dropout, pad_idx):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #self.activation = nn.Sigmoid()\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        #Pack padded sequence for add padding to texts that dont have enoungh length\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        #LSTM return output, hidden state and cell state\n",
    "        packed_output ,(hidden, cell) = self.lstm(packed_embedded)\n",
    "        # Because we use bidirectional so that we have to concatonate two hidden layers \n",
    "        #(the last layer in both foward and backward RNN)\n",
    "        hidden = self.dropout(\n",
    "            torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        \n",
    "        # Because we concatenate two hidden layes so the input dim for fully-connected is doubled\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.958923Z",
     "start_time": "2020-04-04T15:17:26.933884Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(20002, 100)\n",
      "  (lstm): LSTM(100, 100, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "# Get the <pad> id for embedding layer\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
    "\n",
    "model = RNN(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.963804Z",
     "start_time": "2020-04-04T15:17:26.959814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,403,601 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:26.976787Z",
     "start_time": "2020-04-04T15:17:26.964802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pretrained embedding for the vocabulary\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "# Set the <pad> and <unk> token to zero values (because we dont need these token for training)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBED_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBED_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.040325Z",
     "start_time": "2020-04-04T15:17:26.977767Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.045312Z",
     "start_time": "2020-04-04T15:17:29.041323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return accuracy\n",
    "def binary_accuracy(predictions, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "    correct = (rounded_preds==y).float().sum()\n",
    "    acc = correct/len(predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.053290Z",
     "start_time": "2020-04-04T15:17:29.046310Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_step(model, train_iter, optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "        predictions = model(text, text_lengths).squeeze()\n",
    "        loss= criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item()\n",
    "    return total_loss / len(train_iter), total_acc/ len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.062296Z",
     "start_time": "2020-04-04T15:17:29.056283Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_step(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.071244Z",
     "start_time": "2020-04-04T15:17:29.063291Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.086203Z",
     "start_time": "2020-04-04T15:17:29.072241Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_iter, val_iter):\n",
    "    EPOCHS = 10\n",
    "    best_valid_acc = 0\n",
    "    print(\"Start training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_step(model,train_iter,optimizer, criterion)\n",
    "        val_loss, val_acc = val_step(model, val_iter,  criterion)\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if val_acc > best_valid_acc:\n",
    "            best_valid_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'model/model.pt')\n",
    "            print(\"Model saved!\")\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
    "    print(\"Training completed.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.096202Z",
     "start_time": "2020-04-04T15:17:29.088198Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = 0\n",
    "if TRAIN_DATA:\n",
    "    model = train(model,optimizer,criterion,train_iter, valid_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:29.719638Z",
     "start_time": "2020-04-04T15:17:29.097197Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "# Predict a sentence\n",
    "def predict_sentence(model, sentence):\n",
    "    model.eval()\n",
    "    # tokenize the sentence (by spacing)\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    \n",
    "    # Convert tokens into interger\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    \n",
    "    # Compute number of words in the sentence\n",
    "    length = [len(indexed)]\n",
    "    \n",
    "    #Tensorize\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    \n",
    "    #Predict probability\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:17:45.935578Z",
     "start_time": "2020-04-04T15:17:45.918613Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not TRAIN_DATA:\n",
    "    model.load_state_dict(torch.load(\"model/model 89,30.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:18:21.376358Z",
     "start_time": "2020-04-04T15:17:49.728024Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_DIR= \"data/testData.tsv\"\n",
    "ID = data.LabelField(sequential=False)\n",
    "test_fields = [(\"id\", ID), (\"text\", TEXT)]\n",
    "testset = data.TabularDataset(path = TEST_DIR, format = \"tsv\", fields=test_fields, skip_header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:18:24.787399Z",
     "start_time": "2020-04-04T15:18:24.439980Z"
    }
   },
   "outputs": [],
   "source": [
    "ID.build_vocab(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:18:26.364274Z",
     "start_time": "2020-04-04T15:18:26.360286Z"
    }
   },
   "outputs": [],
   "source": [
    "test_iter = data.BucketIterator(testset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                sort_key= lambda x: len(x.text),\n",
    "                                sort_within_batch=True,\n",
    "                                device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:20:15.858250Z",
     "start_time": "2020-04-04T15:20:15.851299Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_test(model, test_iter):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            text, text_lengths = batch.text\n",
    "            output = model(text,text_lengths).squeeze()\n",
    "            predictions = torch.sigmoid(output)\n",
    "            labels = predictions >= 0.6\n",
    "            ids_list = batch.id.cpu().numpy()\n",
    "            labels_list = labels.cpu().numpy()\n",
    "            for i,j in zip(ids_list,labels_list):\n",
    "                result.append([ID.vocab.itos[i],j])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:20:25.822485Z",
     "start_time": "2020-04-04T15:20:17.801578Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [00:08<00:00, 48.78it/s]\n"
     ]
    }
   ],
   "source": [
    "result = predict_test(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:20:27.329058Z",
     "start_time": "2020-04-04T15:20:27.281829Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/submission.csv\", \"w\", newline=\"\") as f:\n",
    "    Writer = csv.writer(f)\n",
    "    Writer.writerow([\"id\"]+[\"sentiment\"])\n",
    "    for i in result:\n",
    "        Writer.writerow([str(i[0])] + [int(i[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:19:57.662845Z",
     "start_time": "2020-04-04T15:19:57.654855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6940540671348572\n"
     ]
    }
   ],
   "source": [
    "print(predict_sentence(model,\"This film sucks\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
