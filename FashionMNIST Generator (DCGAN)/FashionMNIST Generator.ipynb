{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import functions as f\n",
    "import cv2\n",
    "from classes import Discriminator, Generator, weights_init\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda: 0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititate constants\n",
    "PROCESS_DATA = 1 #Change to 1 when training\n",
    "TRAINING_DATA = 1 #Change to 1 if want model to be trained again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititate constants\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_DATA:\n",
    "    dataset = datasets.FashionMNIST(\"data\",train = True,transform=data_transform,download = True)\n",
    "    trainloader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers = 4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show training data size\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show training labels\n",
    "LABELS = dataset.classes\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize some data samples\n",
    "def visualize_samples(NUM_PIC=16):\n",
    "    a = np.random.randint(BATCH_SIZE-NUM_PIC)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img = next(iter(trainloader))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Training Images\")\n",
    "    plt.imshow(np.transpose(torchvision.utils.make_grid(img[0][a:a+NUM_PIC],padding=2, normalize=True),(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make latent vector by creating random Gaussian noise\n",
    "def random_noise(size):\n",
    "    noise = torch.randn(size,LATENT_SIZE,1,1)\n",
    "    noise = Variable(noise).to(device)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate labels for loss fuction\n",
    "def generate_labels(size, label):\n",
    "    if label:\n",
    "        data = torch.ones(size,1)-0.1\n",
    "    else:\n",
    "        data = torch.zeros(size,1)\n",
    "    data = Variable(data).view(-1).to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititate weights for Generator and Discriminator with mean = 0.02, standard deviation = 1\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100,128*8,4,1,0),\n",
    "            nn.BatchNorm2d(128*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128*8,128*4,4,2,1),\n",
    "            nn.BatchNorm2d(128*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128*4,128*2,4,2,1),\n",
    "            nn.BatchNorm2d(128*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128*2,128,4,2,1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128,1,4,2,1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1,128,4,2,1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace= True),\n",
    "\n",
    "            nn.Conv2d(128,128*2,4,2,1, bias=False),\n",
    "            nn.BatchNorm2d(128*2),\n",
    "            nn.LeakyReLU(0.2, inplace= True),\n",
    "\n",
    "            nn.Conv2d(128*2,128*4,4,2,1, bias=False),\n",
    "            nn.BatchNorm2d(128*4),\n",
    "            nn.LeakyReLU(0.2, inplace= True),\n",
    "\n",
    "            nn.Conv2d(128*4,128*8,4,2,1, bias=False),\n",
    "            nn.BatchNorm2d(128*8),\n",
    "            nn.LeakyReLU(0.2, inplace= True),\n",
    "\n",
    "            nn.Conv2d(128*8,1,4,1,0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(D, optimizer, error, real_data, fake_data):\n",
    "    batch_size = real_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    real_data = real_data.to(device)\n",
    "    fake_data = fake_data.to(device)\n",
    "\n",
    "    prediction_real = D(real_data).view(-1)\n",
    "    real_label = generate_labels(batch_size,1)\n",
    "    loss_real = error(prediction_real,real_label)\n",
    "    loss_real.backward()\n",
    "\n",
    "    prediction_fake = D(fake_data).view(-1)\n",
    "    fake_label = generate_labels(batch_size,0)\n",
    "    loss_fake = error(prediction_fake, fake_label)\n",
    "    loss_fake.backward()\n",
    "\n",
    "    D_x = prediction_real.mean().item()\n",
    "    D_g_z1 = prediction_fake.mean().item()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_real.data + loss_fake.data, D_x, D_g_z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(D, optimizer, error, data):\n",
    "    batch_size = data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    data = data.to(device)\n",
    "    prediction = D(data).view(-1)\n",
    "    label = generate_labels(batch_size, 1)\n",
    "    loss = error(prediction, label)\n",
    "    loss.backward()\n",
    "    D_g_z2 = prediction.mean().item()\n",
    "    optimizer.step()\n",
    "    return loss.data, D_g_z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(G,noise):\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        test_img = G(noise).view(-1,1,IMG_SIZE,IMG_SIZE).data.cpu()\n",
    "        img = np.transpose(torchvision.utils.make_grid(test_img[:],padding=2, normalize=True),(1,2,0))\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Generated Images\")\n",
    "        plt.show()\n",
    "    G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate latent vector\n",
    "test_noise = random_noise(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, D_optimizer, G_optimizer, error, trainloader):\n",
    "    EPOCHS = 5\n",
    "    D_loss_list = []\n",
    "    G_loss_list = []\n",
    "    print(\"Start Training.....\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (real_batch,_) in enumerate(trainloader):  \n",
    "            batch_size = real_batch.size(0)\n",
    "            fake_data = G(random_noise(batch_size)).detach()\n",
    "            real_data = Variable(real_batch.view(-1,1,IMG_SIZE,IMG_SIZE))\n",
    "            D_loss,D_x, D_g_z1 = train_discriminator(D,D_optimizer,error,real_data,fake_data)\n",
    "            data = G(random_noise(batch_size))\n",
    "            G_loss, D_g_z2 = train_generator(D,G_optimizer,error,data)\n",
    "            if i%50 == 0 :\n",
    "                print(\"Epoch: ({}/{}), Batch: ({}/{}), D_Loss: {:.4f}, G_Loss: {:.4f}, D(x): {:.4f}, G(D(z)): {:.4f} / {:.4f}\".format(epoch,EPOCHS,i,len(trainloader),D_loss,G_loss,D_x, D_g_z1,D_g_z2))\n",
    "            D_loss_list.append(D_loss)\n",
    "            G_loss_list.append(G_loss)   \n",
    "        torch.save(G.state_dict(), \"model/generator-dcgan2.pth\")\n",
    "        torch.save(D.state_dict(), \"model/discriminator-dcgan2.pth\")\n",
    "        generate_img(G,test_noise)\n",
    "    #plot(D_loss_list,G_loss_list,len(D_loss_list))\n",
    "    return G, D_loss_list,G_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device) \n",
    "D.apply(weights_init)\n",
    "G.apply(weights_init)\n",
    "\n",
    "if TRAINING_DATA:\n",
    "    D_optimizer = torch.optim.Adam(D.parameters(), lr= 0.0002, betas=(0.5, 0.999))\n",
    "    G_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002, betas=(0.5, 0.999))\n",
    "    error = nn.BCELoss()\n",
    "    G, D_loss_list, G_loss_list = train(D,G,D_optimizer,G_optimizer,error,trainloader)\n",
    "else:\n",
    "    G.load_state_dict(torch.load(\"model/generator-dcgan2.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(D_loss_list, G_loss_list, EPOCHS=None):\n",
    "    if EPOCHS is None:\n",
    "        EPOCHS = len(D_loss_list)\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(EPOCHS), D_loss_list)\n",
    "    plt.title(\"Discriminator Loss\")\n",
    "    plt.subplot(212)\n",
    "    plt.plot(range(EPOCHS),G_loss_list)\n",
    "    plt.title(\"Gennerator Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "plot(D_loss_list, G_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noise = f.random_noise(16)\n",
    "generate_img(G,test_noise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
